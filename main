# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
import xgboost
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import roc_auc_score
import torch
from torch import nn
from torch.nn import functional as F
from torch.utils.data import DataLoader, TensorDataset

# Load the dataset and preprocess
def load_and_preprocess_data():
    data = pd.read_csv("Immunotherapies.csv")
    data_drug = pd.read_csv("IMTDrug.csv")

    # Remove unnecessary columns
    data = data.drop(data.columns[[6, 15, 16, 17, 102]], axis=1)

    # Encode categorical variables
    for column in data.select_dtypes(include='object').columns:
        le = LabelEncoder()
        data[column] = le.fit_transform(data[column])
    
    # Encode target variable
    le = LabelEncoder()
    data['Clinical Response.1'] = le.fit_transform(data['Clinical Response.1'])

    return data, data_drug

# Train XGBoost model
def train_xgboost_model(X, y):
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Standardize features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Train XGBoost classifier with hyperparameter tuning
    model = xgboost.XGBClassifier()
    param_grid = {
        'learning_rate': [0.01, 0.1, 0.2],
        'max_depth': [3, 4, 5],
        'min_child_weight': [1, 3, 5],
        'subsample': [0.5, 0.7],
        'colsample_bytree': [0.5, 0.7],
        'n_estimators': [100, 200, 300]
    }
    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=5, verbose=2)
    grid_search.fit(X_train_scaled, y_train)

    # Evaluate model
    y_pred = grid_search.predict(X_test_scaled)
    roc_auc = roc_auc_score(y_test, y_pred)

    return grid_search, roc_auc

# Define CNN model
class CNN(nn.Module):
    def __init__(self, input_shape, num_classes):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3))
        self.pool = nn.MaxPool2d(2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3))
        self.fc1 = nn.Linear(64 * 5 * 12, 128)  # Adjust based on input_shape
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool(x)
        x = F.relu(self.conv2(x))
        x = self.pool(x)
        x = x.view(-1, 64 * 5 * 12)  # Flatten
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Train CNN model
def train_cnn_model(X_train, y_train, X_test, y_test):
    # Prepare data tensors
    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
    y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)
    y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)

    # Create DataLoader
    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

    # Initialize model and training parameters
    model = CNN(input_shape=X_train.shape[1:], num_classes=len(np.unique(y_train)))
    optimizer = torch.optim.Adam(model.parameters())
    loss_fn = nn.CrossEntropyLoss()

    # Training loop
    num_epochs = 10
    for epoch in range(num_epochs):
        for i, (data_batch, target_batch) in enumerate(train_loader):
            # Forward pass
            predictions = model(data_batch)

            # Compute loss
            loss = loss_fn(predictions, target_batch)

            # Backward pass and update weights
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        # Print training information
        print(f'Epoch: {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')

    return model

# Main function
def main():
    # Load and preprocess data
    immunotherapies_data, drug_data = load_and_preprocess_data()

    # Train XGBoost model
    xgboost_model, roc_auc = train_xgboost_model(immunotherapies_data.drop('Clinical Response.1', axis=1), immunotherapies_data['Clinical Response.1'])
    print("XGBoost ROC AUC Score:", roc_auc)

    # Train CNN model
    X_train, X_test, y_train, y_test = train_test_split(drug_data.drop('Treatment', axis=1), drug_data['Treatment'], test_size=0.2, random_state=42)
    cnn_model = train_cnn_model(X_train.values, y_train, X_test.values, y_test)

if __name__ == "__main__":
    main()
